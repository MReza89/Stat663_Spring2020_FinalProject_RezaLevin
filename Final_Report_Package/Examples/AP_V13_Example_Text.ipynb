{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text of Frey and Dueck (2007)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the Supporting Online Material, page 5-6.\n",
    "\n",
    "\"For each sentence in the main text of this manuscript, words delimited by spaces were extracted, punctuation was removed, and words with fewer than 5 characters were discarded. The similarity of sentence i to sentence k was set to the negative sum of the information-theoretic costs (S5) of encoding every word in sentence i using the words in sentence k and a dictionary of all words in the manuscript. For each word in sentence i, if the word matched a word in sentence k, the coding cost for the word was set to the negative logarithm of the number of words in sentence k (the cost of coding the index of the matched word), and otherwise it was set to the negative logarithm of the number of words in the manuscript dictionary (the cost of coding the index of the word in the manuscript dictionary). A word was considered to match another word if either word was a substring of the other.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import Affinity Propagation Source Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "AffinityPackage_import_type=['load_installed_package','load_from_directory'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if AffinityPackage_import_type=='load_installed_package':\n",
    "    \"\"\"pip install -i https://test.pypi.org/simple/ AffinityPropagation-RezaLevin2020-pkg-DukePhDs==0.0.3\"\"\"\n",
    "    from AffinityPropagation_RezaLevin2020_pkg import Src_AP_V13 as AfP\n",
    "else:\n",
    "    \"\"\"can be found in this repository: https://github.com/MReza89/Stat663_Spring2020_FinalProject_RezaLevin\"\"\"\n",
    "    import Src_AP_V13 as AfP # requires to have Src_AP_V13.py in the current directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import libraries related to testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn.cluster as cluster\n",
    "import numpy as np\n",
    "#from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "import time\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('paper_FreyDueck2007.txt') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "sentences = [(i, sentence) for i,sentence in enumerate(re.split('\\. |\\n', text))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(146,\n",
       "  'Yet, to our knowledge, affinity propagation is the first method to make use of this idea to solve the age-old, fundamental problem of clustering data'),\n",
       " (89,\n",
       "  'The reconstruction errors for affinity propagation and k-centers clustering are compared in Fig'),\n",
       " (55,\n",
       "  'For point i, the value of k that maximizes a(i,k) + r(i,k) either identifies point i as an exemplar if k = i, or identifies the data point that is the exemplar for point i'),\n",
       " (27, '')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sentences[i] for i in np.random.choice(len(sentences),4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_key = dict(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_stripped = [(i,\" \".join(sentence.split()).translate(str.maketrans(\"\",\"\",string.punctuation)).lower()) \n",
    "                      for i,sentence in enumerate(re.split('\\. |\\n', text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(110,\n",
       "  'when the number of most accessible cities was constrained to be seven by adjusting the input preference appropriately the cities shown in fig'),\n",
       " (38,\n",
       "  'in the first iteration because the availabilities are zero rik is set to the input similarity between point i and point k as its exemplar minus the largest of the similarities between point i and other candidate exemplars'),\n",
       " (51,\n",
       "  'this message reflects accumulated evidence that point k is an exemplar based on the positive responsibilities sent to candidate exemplar k from other points'),\n",
       " (148, 'â© 2020 github inc')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sentences_stripped[i] for i in np.random.choice(len(sentences_stripped),4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_final = [(index, \" \".join(list_of_words))\n",
    "                   for (index, list_of_words) in [(index, [word for word in sentence_words if len(word) >= 5]) \n",
    "                                         for index,sentence_words in [(index,sentence.split()) \n",
    "                                                                      for index,sentence in sentences_stripped]] \n",
    "                   if len(list_of_words) > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(123,\n",
       "  'degenerate cases energy function multiple minima corresponding multiple fixed points update rules these prevent convergence'),\n",
       " (32,\n",
       "  'availability candidate exemplar point point reflects accumulated evidence appropriate would point choose point exemplar taking account support other points point should exemplar'),\n",
       " (139,\n",
       "  'there input assumed metric nonnegative symmetric satisfying triangle inequality'),\n",
       " (130,\n",
       "  'these techniques improved methods begin large number clusters prune still random sampling pruning decisions cannot recovered')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sentences_final[i] for i in np.random.choice(len(sentences_final),4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_final_data = [sentences for i,sentences in sentences_final]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = set([word for words in [sentence.split() for i,sentence in sentences_final] for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "626"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('clustering identifying subset representative examples important processing sensory signals detecting patterns',\n",
       " 'exemplars found randomly choosing initial subset points iteratively refining works initial choice close solution')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = sentences_final_data[0]\n",
    "k = sentences_final_data[1]\n",
    "i, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-67.03256104061624"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AfP.sentence_similarity(i, k, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the answer. There's only one match ('subset') and sentence i has 11 words:\n",
    "np.allclose(AfP.sentence_similarity(i, k, dictionary) ,\n",
    "            -10*np.log(len(dictionary)) - np.log(len(k.split())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that sentence_similarity is not symmetric. Further, in our implementation, we automatically set sentence similarity to be 0 if the sentences are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-86.10945009709967"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AfP.sentence_similarity(k, i, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AfP.sentence_similarity(i, i, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply affinity propagation to the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the preference\n",
    "# Preference was set to the number of words in the sentence times the negative logarithm of the \n",
    "# number of words in the manuscript dictionary, plus some constant (set to 90 in the paper)\n",
    "constant = -80\n",
    "pref = [len(sentence.split())*(-np.log(len(dictionary))) + constant for sentence in sentences_final_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15 22 38 59] 38\n",
      "Number of exemplars: 4\n",
      "Wall time: 597 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "s_exemplars,s_labels,s_Cluster_Centers,s_last_iteration=AfP.affinity_propagation(sentences_final_data, \n",
    "                                                                             Similarity_metric_=\"Sentences\",\n",
    "                                                                             preference=pref, \n",
    "                                                                             max_iter=200, \n",
    "                                                                             Plot_Clusters=False,Dictionary=dictionary)\n",
    "print(\"Number of exemplars: %i\" % len(s_exemplars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(17,\n",
       "  'affinity propagation takes input collection realvalued similarities between points where similarity indicates point index suited exemplar point'),\n",
       " (25,\n",
       "  'priori points equally suitable exemplars preferences should common value value varied produce different numbers clusters'),\n",
       " (46,\n",
       "  'availability selfresponsibility positive responsibilities candidate exemplar receives other points'),\n",
       " (70,\n",
       "  'affinity propagation found exemplars lower squared error kcenters clustering')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sentences_final[i] for i in s_exemplars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Affinity propagation takes as input a collection of real-valued similarities between data points, where the similarity s(i,k) indicates how well the data point with index k is suited to be the exemplar for data point i',\n",
       " 'If a priori, all data points are equally suitable as exemplars, the preferences should be set to a common value- this value can be varied to produce different numbers of clusters',\n",
       " 'The availability a(i,k) is set to the self-responsibility r(k,k) plus the sum of the positive responsibilities candidate exemplar k receives from other points',\n",
       " 'Affinity propagation found exemplars with much lower squared error than the best of 100 runs of k-centers clustering (Fig']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to full sentences\n",
    "[sentences_key[key] for key in [i for i, sentence in [sentences_final[i] for i in s_exemplars]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
